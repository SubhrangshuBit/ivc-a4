{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e61182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eea22f-e5d0-40d0-8497-d887560b2dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from fcn_dataset import CamVidDataset, rev_normalize\n",
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4479a4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = \"train/\"\n",
    "labels_dir = \"train_labels/\"\n",
    "class_dict_path = \"class_dict.csv\"\n",
    "resolution = (240, 240)\n",
    "class_dict = pd.read_csv(\"CamVid/\" + class_dict_path)\n",
    "camvid_dataset = CamVidDataset(root='CamVid/', images_dir=images_dir, labels_dir=labels_dir, class_dict_path=class_dict_path, resolution=resolution)\n",
    "train_loader = torch.utils.data.DataLoader(camvid_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "val_images_dir = \"val/\"\n",
    "val_labels_dir = \"val_labels/\"\n",
    "val_camvid_dataset = CamVidDataset(root='CamVid/', images_dir=val_images_dir, labels_dir=val_labels_dir, class_dict_path=class_dict_path, resolution=resolution)\n",
    "val_loader = torch.utils.data.DataLoader(val_camvid_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "test_images_dir = \"test/\"\n",
    "test_labels_dir = \"test_labels/\"\n",
    "test_camvid_dataset = CamVidDataset(root='CamVid/', images_dir=test_images_dir, labels_dir=test_labels_dir, class_dict_path=class_dict_path, resolution=resolution)\n",
    "test_loader = torch.utils.data.DataLoader(test_camvid_dataset, batch_size=4, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2979de4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of loading a single sample\n",
    "image, label = camvid_dataset[0]\n",
    "print(image.size())\n",
    "# To visualize or further process, you might want to convert 'label' back to a color image or directly use it for training a segmentation model.\n",
    "label_vis = label.numpy().astype(np.float32)\n",
    "label_vis /= 31.\n",
    "label_vis *= 255.\n",
    "label_vis = label_vis.astype(np.uint8)\n",
    "label_vis = Image.fromarray(label_vis)\n",
    "image_vis = transforms.functional.to_pil_image(rev_normalize(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08630709",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c30070",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c12fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcn_model import FCN8s\n",
    "model = FCN8s(num_classes=32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "num_classes = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9658b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "def loss_fn(outputs, labels):\n",
    "    \"\"\" \n",
    "    In the original paper, the authors mention a per-pixel multinomial logistic loss, which is equivalent to the standard cross-entropy loss.\n",
    "    \"\"\" \n",
    "    return torch.nn.CrossEntropyLoss()(outputs, labels)\n",
    "\n",
    "def calculate_metrics(pred, target, num_classes):\n",
    "    \"\"\" \n",
    "    Calculate the pixel accuracy, mean IoU, and frequency weighted IoU.\n",
    "    \"\"\"\n",
    "    pixel_acc = (pred == target).sum() / (target.shape[0] * target.shape[1])\n",
    "    iou = []\n",
    "    for i in range(num_classes):\n",
    "        intersection = ((pred == i) & (target == i)).sum()\n",
    "        union = ((pred == i) | (target == i)).sum()\n",
    "        iou.append(intersection / union)\n",
    "    mean_iou = np.mean(iou)\n",
    "    freq_iou = np.sum([(target == i).sum() * iou[i] for i in range(num_classes)]) / (target.shape[0] * target.shape[1])\n",
    "    return pixel_acc, mean_iou, freq_iou\n",
    "\n",
    "def eval_model(model, dataloader, device, save_pred=False):\n",
    "    print(\"Starting eval ....\")\n",
    "    model.eval()\n",
    "    loss_list = []\n",
    "    if save_pred:\n",
    "        pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm.tqdm(dataloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss_list.append(loss.item())\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            if save_pred:\n",
    "                pred_list.append(predicted.cpu().numpy())\n",
    "           \n",
    "        loss = sum(loss_list) / len(loss_list)\n",
    "        pixel_acc, mean_iou, freq_iou = calculate_metrics(predicted.cpu().numpy(), labels.cpu().numpy(), num_classes)\n",
    "        print('Pixel accuracy: {:.4f}, Mean IoU: {:.4f}, Frequency weighted IoU: {:.4f}, Loss: {:.4f}'.format(pixel_acc, mean_iou, freq_iou, loss))\n",
    "\n",
    "    if save_pred:\n",
    "        pred_list = np.concatenate(pred_list, axis=0)\n",
    "        np.save('test_pred.npy', pred_list)\n",
    "    model.train()\n",
    "\n",
    "    \n",
    "# Train the model\n",
    "loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(tqdm.tqdm(dataloader_train)):\n",
    "        images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(train_loader), sum(loss_list)/len(loss_list)))\n",
    "            loss_list = []\n",
    "    pixel_acc, mean_iou, freq_iou = calculate_metrics(torch.argmax(outputs, dim=1).cpu().numpy(), labels.cpu().numpy(), num_classes)\n",
    "    print('Pixel accuracy: {:.4f}, Mean IoU: {:.4f}, Frequency weighted IoU: {:.4f}'.format(pixel_acc, mean_iou, freq_iou))\n",
    "    # eval the model        \n",
    "    eval_model(model, val_loader, \"cpu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "otter",
   "language": "python",
   "name": "otter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
